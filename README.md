# Machine_Learning_A-Z_Learning_Code

## Regression Summative Project

Data is retrieved from: https://www.kaggle.com/datasets/fedesoriano/the-boston-houseprice-data

$R^2$ score for different regression models:
  - Decision Tree Regression: -0.09937831917148121
  - Multiple Linear Regression: 0.6506243222334223
  - Multivariate Polynomial Linear Regression: -0.014402932695452897
  - Support Vector Regression: -6.05336504887059
  - Random Forest Regression (with 10 decision trees depth): 0.8031665803048987

It is obvious that the Random Forest Regression model out-performed the other models with an $R^2^$ score of approximately 80%. This implies that approximately 80% of the dependent variable is explained by the independent variable
